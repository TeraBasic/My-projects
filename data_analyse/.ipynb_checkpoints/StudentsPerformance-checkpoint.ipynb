{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ce fichier comporte deux partie, le code et le court rapport à la fin"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Membres du binome:\n",
    "LI Yi \n",
    "Othomane Farajallah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import les packages \n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education lunch  \\\n",
       "0       1              b                           5     1   \n",
       "1       1              c                           1     1   \n",
       "2       1              b                           6     1   \n",
       "3       0              a                           4     0   \n",
       "4       0              c                           1     1   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                       0          72             72             74  \n",
       "1                       1          69             90             88  \n",
       "2                       0          90             95             93  \n",
       "3                       0          47             57             44  \n",
       "4                       0          76             78             75  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import the data et nettoyage des données\n",
    "\n",
    "'''\n",
    "dataset = pd.read_csv( \"StudentsPerformance.csv\")\n",
    "dataset.head()\n",
    "# le niveau de l'éducation est entre 1 et 6\n",
    "dataset['parental level of education'] = dataset['parental level of education'].map(lambda x: x.replace(\"master's degree\",'6').replace(\"some high school\",'3').replace(\"high school\",'2').replace(\"associate's degree\",'4').replace(\"bachelor's degree\",'5').replace('some college','1'))\n",
    "#utiliser 1 pour lunch standard, et 0 pour free/reduced\n",
    "dataset['lunch'] = dataset['lunch'].map(lambda x: x.replace(\"standard\",'1').replace(\"free/reduced\",'0'))\n",
    "# remplacer completed avec 1, none avec 0 \n",
    "dataset['test preparation course'] = dataset['test preparation course'].map(lambda x: x.replace(\"completed\",'1').replace(\"none\",'0'))\n",
    "# remplacer group A (B,C,D,E) avec a,b,c,d,e\n",
    "dataset['race/ethnicity'] = dataset['race/ethnicity'].map(lambda x : x.replace(\"group A\",'a')).replace(\"group B\",'b').replace(\"group C\",'c').replace(\"group D\",'d').replace(\"group E\",'e')\n",
    "# transformer variable catégorie en variable indicateur\n",
    "dataset['gender'] = pd.get_dummies(dataset['gender'])\n",
    "\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utilisateur/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.662651</td>\n",
       "      <td>0.711111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.734940</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3     4         5         6\n",
       "0  1.0  0.8  1.0  0.0  0.72  0.662651  0.711111\n",
       "1  1.0  0.0  1.0  1.0  0.69  0.879518  0.866667\n",
       "2  1.0  1.0  1.0  0.0  0.90  0.939759  0.922222\n",
       "3  0.0  0.6  0.0  0.0  0.47  0.481928  0.377778\n",
       "4  0.0  0.0  1.0  0.0  0.76  0.734940  0.722222"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Normaliser les données\n",
    "'''\n",
    "dataset_new = dataset[['gender','parental level of education','lunch','test preparation course','math score','reading score','writing score']]\n",
    "X = dataset_new.values #returner un numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X)\n",
    "dataset_df = pd.DataFrame(x_scaled)\n",
    "dataset_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 2, 3, 1, 1, 0, 2, 0, 0, 1, 3, 2, 3, 1, 3,\n",
       "       1, 0, 2, 1, 1, 0, 1, 0, 0, 0, 3, 1, 1, 2, 0, 3, 3, 1, 1, 0, 0, 2,\n",
       "       3, 1, 0, 0, 3, 2, 1, 2, 1, 1, 3, 3, 0, 1, 2, 3, 2, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 3, 2, 3, 1, 1, 1, 1, 2, 0, 0, 0, 1, 2, 1, 1, 0, 3, 0,\n",
       "       0, 0, 0, 1, 1, 2, 0, 2, 2, 0, 3, 0, 1, 2, 0, 2, 2, 0, 0, 2, 3, 0,\n",
       "       3, 1, 1, 0, 0, 1, 3, 0, 0, 0, 0, 2, 0, 1, 1, 0, 1, 2, 1, 0, 1, 2,\n",
       "       2, 0, 2, 1, 2, 1, 0, 2, 0, 3, 3, 1, 1, 3, 1, 1, 0, 2, 2, 1, 0, 1,\n",
       "       1, 0, 3, 1, 0, 1, 2, 3, 1, 1, 0, 0, 2, 3, 0, 3, 2, 1, 0, 0, 3, 0,\n",
       "       3, 0, 3, 0, 2, 3, 0, 0, 2, 2, 1, 2, 1, 0, 0, 2, 0, 2, 0, 1, 2, 1,\n",
       "       3, 3, 0, 3, 1, 0, 1, 2, 1, 2, 3, 3, 2, 1, 3, 2, 2, 2, 3, 3, 1, 2,\n",
       "       0, 1, 3, 1, 0, 3, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 0, 1, 1, 2, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 2, 3, 0, 1, 1, 0, 3, 2, 0, 3, 3, 2, 3, 0,\n",
       "       1, 1, 0, 0, 0, 3, 1, 1, 3, 0, 2, 1, 0, 0, 3, 1, 1, 1, 3, 3, 0, 2,\n",
       "       2, 0, 1, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1,\n",
       "       3, 3, 0, 1, 2, 3, 0, 1, 0, 1, 1, 3, 3, 0, 0, 3, 3, 0, 1, 1, 2, 0,\n",
       "       1, 1, 2, 1, 0, 3, 2, 1, 3, 3, 1, 0, 0, 2, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 3, 1, 0, 0, 2, 0, 3, 1, 2, 2, 1, 3, 0, 1, 3, 1, 0,\n",
       "       0, 1, 0, 3, 0, 1, 0, 2, 1, 3, 3, 0, 0, 3, 0, 1, 2, 0, 1, 2, 0, 1,\n",
       "       3, 0, 1, 1, 0, 1, 3, 0, 0, 0, 2, 0, 3, 2, 0, 2, 1, 2, 3, 1, 2, 1,\n",
       "       1, 2, 3, 0, 3, 0, 1, 3, 1, 1, 1, 1, 1, 0, 1, 3, 1, 2, 1, 1, 1, 2,\n",
       "       0, 0, 3, 0, 1, 0, 1, 2, 1, 1, 3, 0, 3, 1, 3, 1, 0, 1, 0, 2, 1, 1,\n",
       "       0, 3, 2, 0, 3, 2, 3, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 2, 3, 1, 1,\n",
       "       0, 1, 1, 3, 2, 2, 3, 0, 0, 0, 0, 2, 0, 3, 0, 1, 0, 0, 1, 0, 3, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 3, 0, 0, 0, 0, 3, 1, 0, 1, 1, 2, 1, 2, 3,\n",
       "       3, 0, 0, 0, 2, 0, 2, 3, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 0, 2, 3, 1,\n",
       "       1, 2, 0, 1, 1, 3, 0, 1, 3, 1, 0, 0, 2, 3, 1, 1, 3, 3, 1, 1, 2, 1,\n",
       "       0, 3, 0, 2, 2, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 3, 0, 0, 2, 0, 2, 0, 0, 0,\n",
       "       0, 1, 1, 2, 3, 1, 2, 2, 3, 2, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 3, 0,\n",
       "       1, 0, 1, 3, 3, 0, 1, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 3, 1,\n",
       "       1, 1, 3, 0, 1, 3, 3, 3, 1, 2, 3, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 3, 2, 0, 2, 1, 1, 1, 0, 3, 3, 0, 0, 3, 0, 0, 0, 1, 0, 0, 2, 0,\n",
       "       3, 1, 1, 1, 1, 3, 2, 0, 0, 1, 0, 3, 2, 0, 0, 2, 3, 2, 3, 1, 1, 2,\n",
       "       0, 2, 3, 1, 3, 1, 0, 1, 3, 1, 1, 3, 1, 1, 1, 3, 0, 0, 1, 1, 1, 1,\n",
       "       3, 2, 2, 1, 2, 0, 1, 0, 1, 2, 3, 2, 3, 0, 2, 0, 1, 0, 0, 2, 0, 1,\n",
       "       1, 1, 3, 3, 1, 3, 0, 3, 0, 2, 3, 0, 3, 0, 2, 0, 3, 0, 1, 3, 0, 3,\n",
       "       1, 2, 0, 3, 1, 3, 1, 0, 2, 2, 0, 0, 0, 1, 3, 3, 1, 1, 1, 1, 0, 2,\n",
       "       0, 2, 0, 2, 3, 0, 0, 3, 2, 3, 3, 1, 3, 0, 3, 1, 3, 3, 1, 0, 1, 0,\n",
       "       1, 0, 2, 0, 3, 1, 3, 2, 3, 1, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       2, 1, 0, 3, 2, 0, 1, 2, 1, 1, 2, 1, 1, 0, 2, 1, 3, 1, 1, 1, 0, 0,\n",
       "       2, 0, 3, 1, 0, 0, 0, 1, 3, 1, 0, 0, 3, 2, 0, 3, 1, 3, 2, 0, 1, 0,\n",
       "       3, 3, 3, 1, 1, 0, 3, 2, 1, 0, 0, 3, 3, 0, 2, 0, 0, 2, 1, 3, 1, 3,\n",
       "       1, 2, 1, 3, 2, 3, 2, 1, 2, 2, 2, 1, 1, 3, 2, 2, 2, 0, 1, 2, 0, 0,\n",
       "       1, 3, 2, 3, 1, 0, 3, 2, 0, 1, 1, 0, 0, 1, 0, 3, 0, 3, 1, 0, 2, 1,\n",
       "       0, 0, 0, 2, 3, 3, 0, 0, 2, 1, 2, 0, 3, 1, 2, 0, 0, 1, 0, 2, 3, 3,\n",
       "       2, 0, 3, 3, 1, 0, 1, 3, 0, 3], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "K-means\n",
    "'''\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(dataset_df)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 0 1 2 0 3 1 1 0 2 2 0 3 0 0 2 0 1 0 2 3 2 0 1 1 2 0 2 0 0 0 0 2 2 3 0\n",
      " 0 3 1 1 0 0 1 0 2 3 0 3 3 2 1 2 2 3 0 3 2 3 0 1 1 1 0 0 2 1 0 1 0 3 3 0 1\n",
      " 2 1 2 3 3 0 0 1 1 2 1 0 0 0 0 0 0 1 2 1 0 1 3 3 0 0 2 3 0 3 3 0 0 3 0 0 3\n",
      " 2 2 0 3 2 0 0 0 0 3 3 3 1 2 0 2 3 2 0 2 1 1 3 1 2 3 2 0 3 0 0 3 2 2 0 2 1\n",
      " 3 1 3 2 3 2 2 3 3 1 3 1 1 3 1 2 0 3 1 3 3 3 3 2 0 0 3 3 3 3 3 3 1 0 0 0 1\n",
      " 1 2 3 1 0 0 3 0 3 3 2 1 1 0 0 3 0 2 0 2 3 2 3 0 0 1 1 0 1 3 3 3 0 1 3 3 2\n",
      " 0 2 3 0 0 2 1 3 2 2 0 2 3 2 1 3 2 2 1 0 0 2 2 2 2 3 0 2 3 0 3 2 2 0 0 3 0\n",
      " 3 3 3 0 0 2 1 0 0 3 0 2 2 0 0 3 2 3 3 0 1 2 2 0 3 0 3 3 0 1 3 2 2 3 0 1 1\n",
      " 3 3 1 1 1 1 3 2 3 2 3 2 0 0 0 2 3 3 3 2 3 2 2 0 3 0 0 0 0 0 2 1 3 0 2 2 3\n",
      " 2 0 0 3 2 0 3 1 0 3 3 2 0 2 3 1 2 0 2 3 0 0 0 2 3 1 0 0 3 0 0 2 1 3 1 0 0\n",
      " 2 3 2 3 0 1 0 3 0 2 0 3 1 0 0 0 0 0 0 2 1 0 2 3 3 1 0 0 2 2 3 2 0 3 0 0 3\n",
      " 0 3 3 3 3 2 3 3 2 3 2 2 1 3 3 3 3 1 0 2 1 1 1 1 0 2 0 2 1 2 1 2 3 3 0 0 0\n",
      " 1 3 1 3 2 2 3 0 0 1 0 1 0 1 0 3 1 1 0 0 3 0 0 1 3 2 3 0 3 0 3 3 3 2 0 2 3\n",
      " 0 1 2 0 2 1 0 3 1 0 0 0 0 0 3 0 3 0 2 0 3 1 3 0 0 2 1 2 0 2 2 1 3 3 3 0 3\n",
      " 3 3 2 0 2 1 3 2 1 0 0 0 3 0 3 3 3 3 3 0 3 3 3 1 0 0 0 1 3 3 0 2 1 1 0 1 2\n",
      " 0 3 1 0 2 3 0 3 3 1 2 3 3 1 1 3 2 0 3 0 1 3 0 3 0 0 0 0 3 0 0 0 0 0 0 1 2\n",
      " 2 0 3 3 1 2 0 0 0 0 0 1 1 2 0 0 0 0 1 0 3 0 0 0 0 2 2 1 0 1 1 3 0 3 1 2 1\n",
      " 3 2 2 3 0 2 2 3 3 2 0 2 3 0 3 2 3 0 0 0 3 1 3 3 3 0 0 1 2 0 2 1 2 0 0 2 3\n",
      " 3 0 2 3 0 1 0 3 3 3 3 3 1 1 0 2 2 3 3 3 3 1 1 1 0 0 3 0 0 0 3 0 3 1 3 0 3\n",
      " 0 3 1 2 2 2 3 3 3 0 2 3 3 3 3 0 1 0 1 3 2 2 3 3 3 0 2 3 1 3 2 0 2 2 3 2 1\n",
      " 2 0 0 3 1 2 2 2 0 3 3 2 1 3 1 0 2 1 3 3 0 0 3 0 2 0 3 3 0 1 2 2 3 0 2 0 0\n",
      " 0 3 3 0 0 3 3 3 3 0 0 1 0 0 0 1 3 0 3 2 0 2 0 3 3 0 0 0 1 0 0 2 2 2 1 3 3\n",
      " 0 3 0 1 0 0 3 0 1 0 0 2 3 0 3 2 0 3 2 3 2 3 2 3 1 0 0 2 3 1 3 2 3 2 0 2 2\n",
      " 0 0 2 2 0 1 0 3 1 0 0 1 3 2 3 1 2 1 1 2 3 3 1 0 1 2 2 0 0 3 3 0 1 0 3 3 1\n",
      " 0 1 3 0 0 3 0 0 1 3 3 3 2 0 3 3 0 2 2 3 0 3 1 0 3 3 0 0 3 0 3 3 1 0 2 0 1\n",
      " 3 1 3 1 0 1 1 1 1 3 1 2 0 3 3 1 0 2 1 0 0 2 0 1 3 2 3 0 3 0 2 2 0 0 2 0 0\n",
      " 0 3 2 0 3 2 0 0 0 3 3 0 0 3 1 2 3 0 0 2 3 3 0 2 0 3 0 3 1 3 0 0 2 3 1 3 3\n",
      " 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "L’algorithme de mixture de gaussienne.\n",
    "'''\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=4).fit(dataset_df)\n",
    "labels = gmm.predict(dataset_df)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate de juste 0.0275\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1-plus-proche voisin\n",
    "\n",
    "'''\n",
    "\n",
    "count_col = dataset_df.shape[0] \n",
    "everage_math = dataset_df[3].mean(axis=0)\n",
    "list_bool = list(range(count_col))\n",
    "for i in range(1,count_col):\n",
    "    if dataset_df[3].iloc[i] > everage_math :\n",
    "        list_bool[i] = 1\n",
    "    else:\n",
    "        list_bool[i] = 0\n",
    "s = pd.Series(list_bool)\n",
    "dataset_df['supérieur_moyen'] = s\n",
    "\n",
    "def dist(x, y):\n",
    "    dist = np.linalg.norm(x - y)\n",
    "    return dist\n",
    "\n",
    "\n",
    "df_np = dataset_df.values\n",
    "split= 4*len(df_np)//5\n",
    "list_class = []\n",
    "num_juste = 0\n",
    "for i in range (split, len(df_np)-1):\n",
    "    dist_min = dist(df_np[i],df_np[0])\n",
    "    voisin = 0\n",
    "    for j in range (1, split-1):\n",
    "        if dist(df_np[i],df_np[j]) < dist_min:\n",
    "            dist_min = dist(df_np[i],df_np[j])\n",
    "            voisin = j\n",
    "    if df_np[voisin][6] == df_np[i][6]:\n",
    "        num_juste += 1\n",
    "    list_class.append(df_np[voisin][6])    \n",
    "#print(list_class)\n",
    "print(\"rate de juste\",num_juste/split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_X :  0.002222339002884\n",
      "p_Y :  0.358\n",
      "p_XY :  0.0\n",
      "The result of f(y=1|X1=female,X2=group A,X3=bachelor's,X4=standard,X5=none) is :  0.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BAYES\n",
    "\"\"\"\n",
    "dataset = pd.read_csv( \"StudentsPerformance.csv\")\n",
    "dataset['supérieur_moyen'] = s\n",
    "length_data = dataset.shape[0]\n",
    "# return p(x)\n",
    "def p_x(colonne,v):\n",
    "    num=0\n",
    "    len_colonne = len(colonne.values)\n",
    "    for i in range(1,len_colonne):\n",
    "        if colonne.iloc[i] == v:\n",
    "            num +=1            \n",
    "    return num/length_data\n",
    "\n",
    "\n",
    "#return p(x|y)\n",
    "def p_xy(col,x,y):\n",
    "    ini = 0\n",
    "    for index, row in dataset.iterrows():\n",
    "        if row[col]== x and row['supérieur_moyen'] == 1:\n",
    "            ini += 1\n",
    "    return ini/length_data\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "def BAYES(x1,x2,x3,x4,x5):\n",
    "    p_x1 = p_x(dataset['gender'],x1)\n",
    "    p_x2 = p_x(dataset['race/ethnicity'], x2)\n",
    "    p_x3 = p_x(dataset['parental level of education'],x3)\n",
    "    p_x4 = p_x(dataset['lunch'],x4) \n",
    "    p_x5 = p_x(dataset['test preparation course'],x5)\n",
    "    p_X = p_x1*p_x2*p_x3*p_x4*p_x5\n",
    "    print('p_X : ',p_X)\n",
    "    p_Y = dataset[dataset.supérieur_moyen==1].shape[0]/length_data\n",
    "    print('p_Y : ',p_Y)\n",
    "    #f(X1,X2,X3,X4,X5|Y=1)\n",
    "    p_XY = p_xy('gender','female',1)*p_xy('race/ethnicity','group A',1)*p_xy('parental level of education',\"bachelor's degree\",1)*p_xy('lunch','standard',1)*p_xy('test preparation course','none',1)\n",
    "    print('p_XY : ',p_XY)\n",
    "    #f(y=1|X1,X2,X3,X4,X5)\n",
    "    p_res = p_XY*p_Y/p_X\n",
    "    return p_res\n",
    "\n",
    "'''\n",
    "TEST\n",
    "'''\n",
    "\n",
    "x1='female'\n",
    "x2='group A'\n",
    "x3=\"bachelor's degree\"\n",
    "x4=\"standard\"\n",
    "x5='none'\n",
    "print(\"The result of f(y=1|X1=female,X2=group A,X3=bachelor's,X4=standard,X5=none) is : \", BAYES(x1,x2,x3,x4,x5))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "      <th>supérieur_moyen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \\\n",
       "0                    none          72             72             74   \n",
       "1               completed          69             90             88   \n",
       "2                    none          90             95             93   \n",
       "3                    none          47             57             44   \n",
       "4                    none          76             78             75   \n",
       "\n",
       "   supérieur_moyen  \n",
       "0                0  \n",
       "1                1  \n",
       "2                1  \n",
       "3                0  \n",
       "4                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64.07788162 66.53426791 64.5046729 ]\n",
      " [69.69553073 73.89385475 74.41899441]]\n",
      "[[230.80827756 209.20397208 224.98983772]\n",
      " [208.64933571 186.00550835 178.89958218]]\n",
      "[0.642 0.358]\n",
      "[1.81556195e-07 1.49501923e-06]\n",
      "[0.17883304 0.82116696]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gaussian naive bayes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import collections \n",
    "import numpy as np\n",
    "from math import *\n",
    "\n",
    "\n",
    "#méthode pour calculer probabilité antérieure P(y)\n",
    "def pre_prob(y):\n",
    "    y_dict = collections.Counter(y)\n",
    "    pre_probab = np.ones(2)\n",
    "    for i in range(0, 2):\n",
    "        pre_probab[i] = y_dict[i]/y.shape[0]\n",
    "    return pre_probab\n",
    "\n",
    "'''\n",
    "retourner le mean et variance P(y|X)\n",
    "'''\n",
    "def mean_var(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    m = np.ones((2, n_features))\n",
    "    v = np.ones((2, n_features))\n",
    "    n_0 = np.bincount(y)[np.nonzero(np.bincount(y))[0]][0]\n",
    "    x0 = np.ones((n_0, n_features))\n",
    "    x1 = np.ones((X.shape[0] - n_0, n_features))\n",
    "    \n",
    "    k = 0\n",
    "    for i in range(0, X.shape[0]):\n",
    "        if y[i] == 0:\n",
    "            x0[k] = X[i]\n",
    "            k = k + 1\n",
    "    k = 0\n",
    "    for i in range(0, X.shape[0]):\n",
    "        if y[i] == 1:\n",
    "            x1[k] = X[i]\n",
    "            k = k + 1\n",
    "        \n",
    "    for j in range(0, n_features):\n",
    "        m[0][j] = np.mean(x0.T[j])\n",
    "        v[0][j] = np.var(x0.T[j])*(n_0/(n_0 - 1))\n",
    "        m[1][j] = np.mean(x1.T[j])\n",
    "        v[1][j] = np.var(x1.T[j])*((X.shape[0]-n_0)/((X.shape[0]\n",
    "                                                      - n_0) - 1))\n",
    "    return m, v # mean et variance \n",
    "\n",
    "'''\n",
    "retourner la probabilité postérieure P(X|Y) avec les parametres mean, variance, et X. \n",
    "'''\n",
    "\n",
    "def prob_feature_class(m, v, x):\n",
    "    n_features = m.shape[1]\n",
    "    pfc = np.ones(2)\n",
    "    for i in range(0, 2):\n",
    "        product = 1\n",
    "        for j in range(0, n_features):\n",
    "            product = product * (1/sqrt(2*3.14*v[i][j])) * exp(-0.5\n",
    "                                 * pow((x[j] - m[i][j]),2)/v[i][j])\n",
    "        pfc[i] = product\n",
    "    return pfc\n",
    "\n",
    "'''\n",
    "Fonction Gaussian naive bayes qui a trois paramètres, X_train, Y_train, et x. \n",
    "Il retourne mean, variance, probalilité antérieure et postérieure, probabilité conditionnelle et resultat de prédiction\n",
    "'''\n",
    "def GNB(X, y, x):\n",
    "    m, v = mean_var(X, y)\n",
    "    pfc = prob_feature_class(m, v, x)\n",
    "    pre_probab = pre_prob(y)\n",
    "    pcf = np.ones(2)\n",
    "    total_prob = 0\n",
    "    for i in range(0, 2):\n",
    "        total_prob = total_prob + (pfc[i] * pre_probab[i])\n",
    "    for i in range(0, 2):\n",
    "        pcf[i] = (pfc[i] * pre_probab[i])/total_prob\n",
    "    prediction = int(pcf.argmax())\n",
    "    return m, v, pre_probab, pfc, pcf, prediction\n",
    "\n",
    "# transformer donnée pandas en donnée numpy \n",
    "X_train = np.array(dataset.iloc[:,[5,6,7]])\n",
    "y_train = np.array(dataset['supérieur_moyen'])\n",
    "\n",
    "\n",
    "'''\n",
    "Test\n",
    "'''\n",
    "# donée pour tester\n",
    "x = np.array([80, 90, 100]) \n",
    "# executer Gaussian Naive Bayes pour donnée test\n",
    "m, v, pre_probab, pfc, pcf, prediction = GNB(X_train, y_train, x)\n",
    "\n",
    "print(m) # mean \n",
    "print(v) # variance \n",
    "print(pre_probab) # probabilité antérieure \n",
    "print(pfc) # probabilité postérieure\n",
    "print(pcf) # probabilité conditionnelle \n",
    "print(prediction) # prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utilisateur/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/utilisateur/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/utilisateur/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/utilisateur/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "la régression logistique\n",
    "'''\n",
    "\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = np.array(dataset.iloc[:,[5,6,7]])\n",
    "Y = np.array(dataset['supérieur_moyen'])\n",
    "\n",
    "# 70% de données pour entrainement, 30% pour tester\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "# normaliser les données\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# entrainer la modele\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "# prédire\n",
    "prepro = logreg.predict_proba(X_test_std)\n",
    "acc = logreg.score(X_test_std,Y_test)\n",
    "print(\"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RAPPORT\n",
    "\n",
    "1）Nettoyage et normalisation des données\n",
    "- le niveau de l'éducation est entre 1 et 6\n",
    "- utiliser 1 pour lunch standard, et 0 pour free/reduced\n",
    "- remplacer completed avec 1, none avec 0 \n",
    "- remplacer group A, group B, group C, group D, group E avec a,b,c,d,e\n",
    "- transformer variable catégorie en variable indicateur\n",
    "- Normaliser les données \n",
    "\n",
    "2）K-means\n",
    "Le processus pour K-means est suivant: \n",
    "- Choisir k points qui représentent la position moyenne des partitions m1(1), …, mk(1) initiales (au hasard);\n",
    "- répeter jusqu'à la convergence\n",
    "    - assigner chaque observation à la partition la plus proche\n",
    "    - mettre à jour la moyenne de chaque cluster\n",
    "    \n",
    "Ici on utilise sklearn, avec sklearn.cluster.KMeans, on divise les échantillons en quatre catégories\n",
    "\n",
    "3）L’algorithme de mixture de gaussienne.\n",
    "Les GMM peuvent être vu comme une version probabilité de K-means, où les clusters correspondent à des gausiennes et chaque point appartient à un cluster avec une certains probabilité. Notre objectif est de trouver l'emsemble des paramètres qui maximisent P(x1),P(x2)....P(Xn).\n",
    "\n",
    "Ici, nous ne pouvons pas utiliser la méthode du maximum de vraisemblance pour trouver le paramètre qui maximise la vraisemblance, car pour chaque point de données observé, on ne sait pas à quelle sous-distribution il appartient.  Donc, on peut utiliser l'algo EM(Expectation Maximisation) pour résoudre ce problème.\n",
    "\n",
    "Avec sklearn.mixture.GaussianMixture, on divise aussi les échantillons en quatre catégories\n",
    " \n",
    "4)K-plus-proche voisin\n",
    "Pour estimer la sortie associée à une nouvelle entrée x, la méthode des k plus proches voisins consiste à prendre en compte les k échantillons d'apprentissage dont l’entrée est la plus proche de la nouvelle entrée x, selon une distance à définir. Ici on utilise la distance euclidienne. Par exemple, on suppose k=5, si 3 voisins les plus proches de la entrée x ont la sortie 1, on peut dire aussi x a la sortie 1.  \n",
    "\n",
    "Ici on prend en compte qu'un seul voisin\n",
    "Le processus pour le réaliser est suivant: \n",
    "    - Traintement des données. On calcule la médian des notes mathématique, et ajoute une colonne “Supérieur_moyen” , si math score inférieur au score médian, on met 0 dans la lingne, si math score supérieur au  score médian, on met 1 dans la ligne.\n",
    "    - On écrit un méthode pour calculer la distance euclidienne.\n",
    "    - On prend 80% des échantillons comme échantillons entraîné, les autres comme donnée test. On calcule la distance euclidienne entre un échantillons de test et tous les échantillons entraîné, on choisit l’échantillon entraîné qui a la distance minimum avec l’échantillon de test. Selon algo 1-plus-proche voisin, Ils ont la même valeur de “Supérieur_moyen”\n",
    "\n",
    "5）Bayes \n",
    "Selon la théorème bayes, on sais que \n",
    "    - P(Y=1|X1,X2,X3,X4,X5)=P(X1,X2,X3,X4,X5|Y=1)*P(Y=1)/P(X1,X2,X3,X4,X5)\n",
    "    - P(X1,X2,X3,X4,X5) = P(X1)*P(X2)*P(X3)*P(X4)*P(X5)\n",
    "    - P(Y1=1) = num(1)/total\n",
    "    - P(X1,X2,X3,X4,X5|Y=1)=P(X1|Y=1)*P(X2|Y=1)*P(X3|Y=1)*P(X4|Y=1)*P(X5|Y=1)\n",
    "\n",
    "On écrit une méthode pour calculer  return P(x)\n",
    "On écrit une méthode pour calculer P(X|Y)\n",
    "On écrit une méthode qui prend 5 paramètres, et retourne P(Y=1|X1,X2,X3,X4,X5)\n",
    "\n",
    "6）Gaussian naive bayes\n",
    "    Bayes Naive est un algorithme très utile, spécialement pour l’analyse de texte et la classification générale, il a de nombreuses configurations différentes, comme: Gaussian Naive Bayes, Bernoulli Naive Bayes etc. Ici on utilise Gaussian Naive Bayes,il suppose que la distribution de probabilité conditionnelle de paramètre satisfait à la distribution gaussienne.\n",
    "    Le processus pour le réaliser est un peu pareille comme \n",
    "        - On écrit une méthode pour calculer probabilité antérieure P(y)\n",
    "        - Une méthode pour retourner le mean et variance P(Y|X)\n",
    "        - On écrit une méthodes pour retourner la probabilité postérieure P(X|Y) avec les paramètres mean, variance, et X. \n",
    "        - Une méthodes pour calculer les deux probabilités conditionnelles pour une instance donnée et retourne les valeur comme mean, variance etc.\n",
    "\n",
    "7）La régression logistique\n",
    "Le processus pour réaliser la régression logistique est suivant: \n",
    "    - Recherche de la fonction h (la fonction de prédiction)\n",
    "    - Fonction de construction J (fonction de perte)\n",
    "    - Trouver un moyen de minimiser la fonction J et trouver le paramètre de régression (θ)\n",
    "ici on utilise sklearn pour faire ça\n",
    "on utilise 70% de données pour entrainement, 30% pour tester\n",
    "on a un résultat 66% Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
